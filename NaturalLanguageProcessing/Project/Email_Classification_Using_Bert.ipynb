{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1qY2cNrjYeb"
      },
      "source": [
        "OVERVIEW:\n",
        "\n",
        "In this tutorial notebook, we will be covering a simple approach to email classification(spam or not spam) using BERT\n",
        "\n",
        "Steps are:\n",
        "- We will load our data - mainly sentences and labels-span or not spam\n",
        "- Load these in bert to generate an contextualized embedding vector of length 768\n",
        "\n",
        "- - We will first apply preprocessing using the preprocessor object , refer the documentation\n",
        "\n",
        "- - We will pass this preprocessed text to our model to generate the contexutailized embedding vector\n",
        "\n",
        "\n",
        "- Finally pass this embedding vector to single neuron in output to do binary classificaton\n",
        "\n",
        "- For maximizing performance we will be balancing our dataset and use a dropout layer to regularize the model and prevent overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIDRx50hmOHn"
      },
      "source": [
        "# Loading Dependencies\n",
        "\n",
        "Includes\n",
        "- Tensorflow_hub : Place where all tenseorflow pretrained models are stored.\n",
        "- Pandas : For data loading, manipulation and wrangling.\n",
        "- Tensorflow_text : Allows addditional NLP text processing capablities outside scope of tensorflow\n",
        "- Skelarn : For doing data evaluation and splitting\n",
        "- Matplotlib : For visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rHL-6ICMjR02"
      },
      "outputs": [],
      "source": [
        "import tensorflow_text as text\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxCW4LI2nTDP"
      },
      "source": [
        "# Loading Data\n",
        "\n",
        "- Read Data\n",
        "- Display data\n",
        "USING PANDAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ezq6cjlanZ-W"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "df_first = pd.read_csv('./spam_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "izsIx-jEnlqE",
        "outputId": "79b8be85-76c2-406c-c319-f88df9e8149d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 target                                               text\n",
              "0           0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1           1    ham                      Ok lar... Joking wif u oni...\n",
              "2           2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3           3    ham  U dun say so early hor... U c already then say...\n",
              "4           4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_first.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EClfcOCSBqtJ",
        "outputId": "5882bf7a-3a14-457e-9e59-b52b28c64d19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target                                               text\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rearrange the columns\n",
        "df_first.drop(columns=df_first.columns[0], axis=1, inplace=True)\n",
        "df_first.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WcB-SVJWB4NN",
        "outputId": "92c73603-3f64-4e19-e4e1-798bc8edb802"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rename columns\n",
        "df_first = df_first.rename({'target': 'Category', 'text': 'Message'}, axis=1)\n",
        "df_first.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmPj4GdntAP"
      },
      "source": [
        "# Data Analysis\n",
        "\n",
        "- Check the description by grouping by category :\n",
        "* no of data points for each category - count\n",
        "* no of unique values in each category - unique\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o915XlVSnnWC",
        "outputId": "f66b6dce-fc76-4812-eec6-b884a0c7af16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check count and unique and top values and their frequency\n",
        "df_first['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2xNm29josry"
      },
      "source": [
        "**Clearly dataset is imbalanced - not so much but still it can affect our model. Need to use some type of regulariztion like downsampling dataset for mazority class**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXTBy8V6AAvz"
      },
      "source": [
        "# Downsampling Dataset \n",
        "\n",
        "**Includes:**\n",
        "- Check percentage of unbalances.\n",
        "- Creating 2 new dataframes out of existing one.\n",
        "- Taking any random minority no of samples - `(747)` for majority class`(4825)`.\n",
        "- Creating a balanced dataset by concating 2 new data frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JAVn93gTAn4x",
        "outputId": "b48aea71-c8e6-4542-bafa-cc847bf71252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.15%'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check percentange of data - states how much data needs to be balanced\n",
        "str(round(747/4825,2))+'%'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtvNODIWC_or",
        "outputId": "e23c03a8-7766-4ef6-e1ae-6299b7908e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spam Dataset Shape: (747, 2)\n",
            "Ham Dataset Shape: (4825, 2)\n"
          ]
        }
      ],
      "source": [
        "# creating 2 new dataframe as df_hm , df_spm\n",
        "\n",
        "df_spm = df_first[df_first['Category']=='spam']\n",
        "print(\"Spam Dataset Shape:\", df_spm.shape)\n",
        "\n",
        "df_hm = df_first[df_first['Category']=='ham']\n",
        "print(\"Ham Dataset Shape:\", df_hm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHgH0so1DwDq",
        "outputId": "af9fa542-6434-4c83-b29f-291c13f5bbf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(747, 2)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# downsampling ham dataset - take only random 747 example\n",
        "# will use df_spm.shape[0] - 747\n",
        "\n",
        "df_hm_downsampled = df_hm.sample(df_spm.shape[0])\n",
        "df_hm_downsampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9sSro4RAESK4",
        "outputId": "27a7c3e9-5171-4ad0-b7d8-468fa358fb81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spam</td>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Category                                            Message\n",
              "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5      spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "8      spam  WINNER!! As a valued network customer you have...\n",
              "9      spam  Had your mobile 11 months or more? U R entitle...\n",
              "11     spam  SIX chances to win CASH! From 100 to 20,000 po..."
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# concating both dataset - df_spm and df_hm_balanced to create df_balanced dataset\n",
        "df_balanced = pd.concat([df_spm , df_hm_downsampled])\n",
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDBVrmF1FZzj",
        "outputId": "7956588c-8ff3-4c34-b372-af1ff2aefbea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spam    747\n",
              "ham     747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_balanced['Category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L_eL5oWWGVSg",
        "outputId": "44aec6f9-742e-4bde-952e-aca9eb349f02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4968</th>\n",
              "      <td>spam</td>\n",
              "      <td>You can donate £2.50 to UNICEF's Asian Tsunami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5112</th>\n",
              "      <td>spam</td>\n",
              "      <td>December only! Had your mobile 11mths+? You ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1214</th>\n",
              "      <td>ham</td>\n",
              "      <td>Yeah, probably but not sure. Ilol let u know, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2438</th>\n",
              "      <td>spam</td>\n",
              "      <td>For ur chance to win £250 cash every wk TXT: P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>ham</td>\n",
              "      <td>I thank you so much for all you do with selfle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ah, well that confuses things, doesnt it? I th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5456</th>\n",
              "      <td>spam</td>\n",
              "      <td>For the most sparkling shopping breaks from 45...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3097</th>\n",
              "      <td>ham</td>\n",
              "      <td>We walked from my moms. Right on stagwood pass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>spam</td>\n",
              "      <td>Your next amazing xxx PICSFREE1 video will be ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category                                            Message\n",
              "4968     spam  You can donate £2.50 to UNICEF's Asian Tsunami...\n",
              "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
              "5112     spam  December only! Had your mobile 11mths+? You ar...\n",
              "1214      ham  Yeah, probably but not sure. Ilol let u know, ...\n",
              "2438     spam  For ur chance to win £250 cash every wk TXT: P...\n",
              "3021      ham  I thank you so much for all you do with selfle...\n",
              "5099      ham  Ah, well that confuses things, doesnt it? I th...\n",
              "5456     spam  For the most sparkling shopping breaks from 45...\n",
              "3097      ham  We walked from my moms. Right on stagwood pass...\n",
              "2575     spam  Your next amazing xxx PICSFREE1 video will be ..."
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_balanced.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27ydr2kTqpzd"
      },
      "source": [
        "# Data Prepration\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl1a8-UMr8Og"
      },
      "source": [
        "1. Create Numerical Repersentation Of Category - One hot encoding\n",
        "* Create a new column\n",
        "* Use `df[col].apply(lambda function)`\n",
        "* Lambda Function - if spam return 1, else return 0 (for ham) - ternary operators : [`lambda x : value expression else value`]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Mdyy7sRSohat"
      },
      "outputs": [],
      "source": [
        "# creating numerical repersentation of category - one hot encoding\n",
        "df_balanced['spam'] = df_balanced['Category'].apply(lambda x:1 if x=='spam' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Klio3EjJqXMO",
        "outputId": "76404f55-c03d-40a3-f743-b8c18996a66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4485</th>\n",
              "      <td>ham</td>\n",
              "      <td>Shopping? Eh ger i toking abt syd leh...Haha</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5463</th>\n",
              "      <td>ham</td>\n",
              "      <td>U GOIN OUT 2NITE?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4311</th>\n",
              "      <td>spam</td>\n",
              "      <td>Someone U know has asked our dating service 2 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>spam</td>\n",
              "      <td>Reply with your name and address and YOU WILL ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category                                            Message  spam\n",
              "4485      ham       Shopping? Eh ger i toking abt syd leh...Haha     0\n",
              "5463      ham                                  U GOIN OUT 2NITE?     0\n",
              "4311     spam  Someone U know has asked our dating service 2 ...     1\n",
              "1227     spam  Reply with your name and address and YOU WILL ...     1"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# displaying data - spam -1 , ham-0\n",
        "df_balanced.sample(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3ww8PWwsEwl"
      },
      "source": [
        "2. Do train-test split\n",
        "* split dataset into 80-20 ratio with 80% train and remaing as test\n",
        "* for eveness of data we will use `stratify` agrument which ensures same ratio of both category is loaded for each case, even if one categoy has more training samples - prevents overfitting \n",
        "\n",
        "Store our data in: \n",
        "- `X_train, y_train` - traininge set(training_data and labels respectively)\n",
        "- `X_test,, y_test` - testing set(testing_data and labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "azGEpOO5qddM"
      },
      "outputs": [],
      "source": [
        "# loading train test split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "TbfvNNfFshf9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(df_balanced['Message'], df_balanced['spam'],\n",
        "                                                    stratify = df_balanced['spam'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuxPdCk5tKDe",
        "outputId": "d970274d-b4f4-4145-f2c8-18f769c41db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    560\n",
              "1    560\n",
              "Name: spam, dtype: int64"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for startification\n",
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ve-U2RtRJA",
        "outputId": "d51bd9d5-f651-4ec4-9058-b25496b8be38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "560/560"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2QUqTH7tf8v",
        "outputId": "bfbf7e5c-d450-4bf5-d95b-44ee90dc74b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    187\n",
              "0    187\n",
              "Name: spam, dtype: int64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwj-jZvyttY1",
        "outputId": "1d9ccd02-1ec8-4b65-e5fc-bf36fc11e794"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "187/187"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy-G15ygtx6l"
      },
      "source": [
        "***-> Almost similar, means data is downsampled now ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGxsu6M5uKeM"
      },
      "source": [
        "# Model Creation \n",
        "\n",
        "Our Model is BERT , which will do 2 thing:\n",
        "- Preporcess our training data that will be feeded - includes **adding additional token CLF , PAD and SEP** to genrate `input_mask`, `input_type_ids`, `input_word_ids(token given to each word in  sentences)` \n",
        "\n",
        "* Note: no of words in sentence - 128/ max length of sentence can be 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFLR3w1Ywdp9"
      },
      "source": [
        "## Downloading BERT\n",
        "\n",
        "Model specification : \n",
        "- Layers - 12\n",
        "- Hidden layers - 768 - embedding size\n",
        "- Attention - 12\n",
        "Name - Bert Small\n",
        "---\n",
        "This model has 2 parts:\n",
        "- Bert_preprocessor - preprocess the text to be BERT ready\n",
        "- Bert_encoder - do the actual encoding\n",
        "---\n",
        "Steps:\n",
        "> Preprocessor\n",
        "* create a keras hub layer from the preprocessing url \n",
        "\n",
        "> Encoder\n",
        "* create a keras hub layer from the encoder/ model url\n",
        "\n",
        "Awesome functionality provided by Tf hub API\n",
        "\n",
        "\n",
        "                            +\n",
        "\n",
        "Creating our own model using functional model api- link old layers to new layers rather than building it(in a sequential way) and allows sharing of layers too\n",
        "\n",
        "Info:\n",
        "- Text the embedding as input - text_input\n",
        "- Create a Sinlge output dense layer\n",
        "- Add dropout to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "kY4GZRkhuDFF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:05:12.641495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "# downloading preprocessing files and model\n",
        "bert_pre_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_enc_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
        "bert_preprocessor = hub.KerasLayer(bert_pre_url)\n",
        "bert_encoder = hub.KerasLayer(bert_enc_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o31hT-Q6xqM"
      },
      "source": [
        "## Process And Encode Data\n",
        "\n",
        "Use functional API to process and encode data in the layers itself\n",
        "\n",
        "- Create a input layers with shape() , type - tf.string, and layer name - text - `TEXT_INPUT`\n",
        "\n",
        "- Pass TEXT_INPUT into bert_prerocessor - `PREPROCESSED TEXT[*]`\n",
        "- Pass the above[*] to encoder - `EMBEED`\n",
        "- pass pooled_outputs of EMBEED to dropout layer - `DROPOUT`\n",
        "- create a dense layer with activation as `sigmoid` `OUTPUTS`\n",
        "- Create out MODEL (inputs - text_input, outputs - dropout) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "XoQD_1tM9YUa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "u18D2Edx9UtU"
      },
      "outputs": [],
      "source": [
        "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'Inputs')\n",
        "preprocessed_text = bert_preprocessor(text_input)\n",
        "embeed = bert_encoder(preprocessed_text)\n",
        "dropout = tf.keras.layers.Dropout(0.1, name = 'Dropout')(embeed['pooled_output'])\n",
        "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'Dense')(dropout)\n",
        "\n",
        "# creating final model\n",
        "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtVPEIWI_xfL",
        "outputId": "1010efd7-3b96-42a2-c477-41122d617c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Inputs (InputLayer)            [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     {'input_mask': (Non  0           ['Inputs[0][0]']                 \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)     {'default': (None,   109482241   ['keras_layer_2[0][0]',          \n",
            "                                768),                             'keras_layer_2[0][1]',          \n",
            "                                 'encoder_outputs':               'keras_layer_2[0][2]']          \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " Dropout (Dropout)              (None, 768)          0           ['keras_layer_3[0][13]']         \n",
            "                                                                                                  \n",
            " Dense (Dense)                  (None, 1)            769         ['Dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# check summary of model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WivCcdI4ABFv"
      },
      "source": [
        "##  Compiling model\n",
        "\n",
        "- Optimizer - ADAM\n",
        "- Loss - binary_crossentropy\n",
        "- metrics - accuracy , precesion and recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "fExyJ0OIAT_6"
      },
      "outputs": [],
      "source": [
        "Metrics = [tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
        "           tf.keras.metrics.Precision(name = 'precision'),\n",
        "           tf.keras.metrics.Recall(name = 'recall')\n",
        "           ]\n",
        "\n",
        "model.compile(optimizer ='adam',\n",
        "               loss = 'binary_crossentropy',\n",
        "               metrics = Metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "cellView": "form",
        "id": "6614TFszD3FU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "#@title Optional \n",
        "# optional - defining tensorflow callbacks\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "\n",
        "!rm -rf ./logs/\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmImktpaAxTz"
      },
      "source": [
        "##  Training Model\n",
        "- Recomended to use `GPU` - providing so many training data\n",
        "\n",
        "- We traing our model on training set\n",
        "- For 10 epochs only - so model don't overfit - given enough training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "fwUasCWTF_fw",
        "outputId": "31d89712-c993-429f-bb11-8c4034424b8e"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "809-rT7VAiZx",
        "outputId": "1691985d-cf2f-4701-adde-58946b9d9eb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:05:39.005846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 138s 4s/step - loss: 0.5979 - accuracy: 0.6938 - precision: 0.6867 - recall: 0.7125\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    history = model.fit(X_train, y_train, epochs = 1 , callbacks = [tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXwqfPckKkAW"
      },
      "source": [
        "# Model Evaluation \n",
        "\n",
        "- Evaulating model performance \n",
        "using `model.evaluate(X_test, y_test)`\n",
        "\n",
        "- Predicting X_test - `y_pred`\n",
        "-- Checking its values as 1 or 0 \n",
        "- Getting Confusion matrix\n",
        "-- Flattening y_pred \n",
        "-- Ploting consufion matrix\n",
        "\n",
        "- Getting classification report "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8zbbvJiLmca",
        "outputId": "55522ba6-a362-4c8d-e004-c439a199df20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:07:52.359050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 37s 3s/step - loss: 0.5225 - accuracy: 0.8476 - precision: 0.8571 - recall: 0.8342\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Evaluating performace\n",
        "    model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WuOPIw6LyW4",
        "outputId": "6aceaf34-58fa-48ab-9499-5bbb9ac4cd7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:08:28.850675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 37s 3s/step\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # getting y_pred by predicting over X_text and flattening it\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = y_pred.flatten() # require to be in one dimensional array , for easy maniputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmYR-3khME7D",
        "outputId": "97219b32-75ab-490f-e94d-b7b2faade7e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the results y_pred\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.where(y_pred>0.5,1,0 )\n",
        "y_pred "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib0Qbl1gMkuh"
      },
      "source": [
        "**Not so understandable so plotting confusion matrix and classification report  for good visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "c8eDOUPNMxR8"
      },
      "outputs": [],
      "source": [
        "# importing consfusion maxtrix\n",
        "from sklearn.metrics import confusion_matrix , classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmCMGKCCexbd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_sRMBZ3NQrg",
        "outputId": "ee81bba5-ce23-4524-bcc1-d83c95ae8f92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[161,  26],\n",
              "       [ 31, 156]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating confusion matrix \n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "DBaZcsKLNQgc"
      },
      "outputs": [],
      "source": [
        "# plotting as graph - importing seaborn\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "BO4qrEhpNxb6",
        "outputId": "d5dced0e-e624-485e-fe44-c7cddaf71354"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Actual')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# creating a graph out of confusion matrix\n",
        "sns.heatmap(cm, annot = True, fmt = 'd')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtyfSxbfOdhK",
        "outputId": "0f1c3a83-2a3f-46f8-9fff-f7d4259336a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       187\n",
            "           1       0.86      0.83      0.85       187\n",
            "\n",
            "    accuracy                           0.85       374\n",
            "   macro avg       0.85      0.85      0.85       374\n",
            "weighted avg       0.85      0.85      0.85       374\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# printing classification report\n",
        "print(classification_report(y_test , y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIFoIlX-RL0Q"
      },
      "source": [
        "**Good Precesion And Recall Score, but can be improved** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQKhQkH0JXto"
      },
      "source": [
        "# Model Prediction\n",
        "\n",
        "- We will be predicting data on text coprus,\n",
        "value > 5 is most likely be `spam`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ELNZGav_GUu0"
      },
      "outputs": [],
      "source": [
        "predict_text = [\n",
        "                # Spam\n",
        "                'We’d all like to get a $10,000 deposit on our bank accounts out of the blue, but winning a prize—especially if you’ve never entered a contest', \n",
        "                'Netflix is sending you a refund of $12.99. Please reply with your bank account and routing number to verify and get your refund', \n",
        "                'Your account is temporarily frozen. Please log in to to secure your account ', \n",
        "\n",
        "                #ham\n",
        "                'The article was published on 18th August itself',\n",
        "                'Although we are unable to give you an exact time-frame at the moment, I would request you to stay tuned for any updates.',\n",
        "                'The image you sent is a UI bug, I can check that your article is marked as regular and is not in the monetization program.'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIzJRXQdKq6R",
        "outputId": "82819bd3-c4eb-480f-e5ad-936de93922d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:09:06.550396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    test_results = model.predict(predict_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "8uzjeab5ReLG"
      },
      "outputs": [],
      "source": [
        "output = np.where(test_results>0.5,'spam', 'ham') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AMrf98QSZ-P",
        "outputId": "fb960c99-3989-4e83-9623-9bd060d6bf71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['ham'],\n",
              "       ['spam'],\n",
              "       ['spam'],\n",
              "       ['ham'],\n",
              "       ['ham'],\n",
              "       ['ham']], dtype='<U4')"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDOfN-rBzga0"
      },
      "source": [
        "# Additional Content\n",
        "\n",
        "- Create a function which will take in `sentece array` and return the embedding vector for entire sentece -`pooled_output`\n",
        "---\n",
        "STEPS:\n",
        "To do so inside the we follow 3 steps:\n",
        "\n",
        "1. We `pass the sentence array to bert_preprocessor` as it can act a function point and name it **preprocessed_text**\n",
        "\n",
        "2. Now we `pass this preprocessed sentence into encoder` and it return a embedding vector dictonary \n",
        "\n",
        "3. We retun only the `pooled output` as we are interested in only the entire sentence encoding\n",
        "\n",
        "---\n",
        "Later we compare the embedding vector using `cosine - similarity from sklearn.metrics.parwiase` class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "oDomsxWQy6Vf"
      },
      "outputs": [],
      "source": [
        "def get_embedding(sentence_arr):\n",
        "    'takes in sentence array and return embedding vector'\n",
        "    preprocessed_text = bert_preprocessor(sentence_arr)\n",
        "    embeddings = bert_encoder(preprocessed_text)['pooled_output']\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "hH_826cN1fiE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-09 11:09:07.745461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
            "2022-07-09 11:09:07.838499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    e = get_embedding([\n",
        "                'We’d all like to get a $10,000 deposit on our bank accounts out of the blue, but winning a prize—especially if you’ve never entered a contest',\n",
        "                'The image you sent is a UI bug, I can check that your article is marked as regular and is not in the monetization program.'\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "cOhi0ssS1z1U"
      },
      "outputs": [],
      "source": [
        "# load similartiy score\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE-fw_0j2-oM",
        "outputId": "5b12b59e-5055-4b5b-f1bc-eaca181b0afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity score between 1st sentence(spam) and second sentence(spam) : [[0.85391974]]\n"
          ]
        }
      ],
      "source": [
        "# check similarity score\n",
        "print(f'Similarity score between 1st sentence(spam) and second sentence(spam) : {cosine_similarity([e[0]] , [e[1]])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOhqqrRYLu25"
      },
      "source": [
        "* Not exact similarity, may show un expected results as can be seen - they are somewhat similar but its false as spam and actual can't be same"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Email Classification Using Bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0ad69a7234e77025977948457bfdf66ef0655820e493146801cdca2aeeff8a65"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
